{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf011ffb",
   "metadata": {},
   "source": [
    "# Data & Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0eaf8",
   "metadata": {},
   "source": [
    "Initializing some helper functions that would be used later during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f46372-a860-43d2-ae8d-2da205b4f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Some helper functions for PyTorch, including:\n",
    "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
    "    - msr_init: net parameter initialization.\n",
    "    - progress_bar: progress bar mimic xlua.progress.\n",
    "'''\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "seed_v = 42\n",
    "\n",
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "\n",
    "_, term_width = shutil.get_terminal_size()\n",
    "term_width = int(term_width)\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6fbffa",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af350f6c",
   "metadata": {},
   "source": [
    "Here, we define our model - **SimpleDLA class**. In our experiments, we use the DLA (https://arxiv.org/abs/1707.06484) architecture with ZigZag-aligned modifications, specifically with a modified first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f24bfc8-8dca-4c30-bf47-c158f5b23f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Simplified version of DLA in PyTorch.\n",
    "Note this implementation is not identical to the original paper version.\n",
    "But it seems works fine.\n",
    "See dla.py for the original paper version.\n",
    "Reference:\n",
    "    Deep Layer Aggregation. https://arxiv.org/abs/1707.06484\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Root(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1):\n",
    "        super(Root, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            stride=1, padding=(kernel_size - 1) // 2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        x = torch.cat(xs, 1)\n",
    "        out = F.relu(self.bn(self.conv(x)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Tree(nn.Module):\n",
    "    def __init__(self, block, in_channels, out_channels, level=1, stride=1):\n",
    "        super(Tree, self).__init__()\n",
    "        self.root = Root(2*out_channels, out_channels)\n",
    "        if level == 1:\n",
    "            self.left_tree = block(in_channels, out_channels, stride=stride)\n",
    "            self.right_tree = block(out_channels, out_channels, stride=1)\n",
    "        else:\n",
    "            self.left_tree = Tree(block, in_channels,\n",
    "                                  out_channels, level=level-1, stride=stride)\n",
    "            self.right_tree = Tree(block, out_channels,\n",
    "                                   out_channels, level=level-1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.left_tree(x)\n",
    "        out2 = self.right_tree(out1)\n",
    "        out = self.root([out1, out2])\n",
    "        return out\n",
    "\n",
    "\n",
    "class SimpleDLA(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, num_classes=10):\n",
    "        super(SimpleDLA, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer3 = Tree(block,  32,  64, level=1, stride=1)\n",
    "        self.layer4 = Tree(block,  64, 128, level=2, stride=2)\n",
    "        self.layer5 = Tree(block, 128, 256, level=2, stride=2)\n",
    "        self.layer6 = Tree(block, 256, 512, level=1, stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        out = self.base(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        z = out.view(out.size(0), -1)\n",
    "        out = self.linear(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9925d99",
   "metadata": {},
   "source": [
    "# Initialize Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d1461",
   "metadata": {},
   "source": [
    "Here, we define the optimization parameters and the functions for **train** and **test**. As described in the paper, the first inference of our method is performed with a \"blank\" additional input, while the second inference incorporates the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91fc8cf2-836b-4ae5-b8c4-c8c74e426234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import tqdm\n",
    "\n",
    "    \n",
    "# Creating our model\n",
    "device = \"cuda\"\n",
    "print('==> Building model..')\n",
    "net = SimpleDLA()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Class that stores hyper-parameters for the optimization\n",
    "class Args:\n",
    "  def __init__(self):\n",
    "    self.lr = 0.001\n",
    "    self.resume = False\n",
    "    self.checkpoint = \"cifar_zigzag\"\n",
    "    self.batch_size = 56\n",
    "\n",
    "args = Args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.batch_size, shuffle=True, num_workers=64)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=args.batch_size, shuffle=False, num_workers=64)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./checkpoint/{args.checkpoint}.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "C = 0 # this parameter defines \"blank\" value for the input\n",
    "S = 10 # this parameter defines scale of the additional input\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    t = tqdm.trange(len(trainset) // args.batch_size + 1, desc='Current Loss = ', leave=True)\n",
    "\n",
    "    for _, (batch_idx, (inputs, targets)) in zip(t, enumerate(trainloader)):\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        batch_size, _, H, W = inputs.shape\n",
    "\n",
    "        # creating \"blank\" inputs for the first inferense\n",
    "        # in this case, it's 4d tensor filled with constant C\n",
    "        targets_1 = C * torch.ones(batch_size, 1, H, W).to(inputs.device)\n",
    "        x1 = torch.cat([inputs, targets_1 / S], dim=1)\n",
    "\n",
    "        # creating additional input for the second inference\n",
    "        # in this case, this input filled with ground truth classes\n",
    "        targets_2 = torch.ones(batch_size, 1, H, W).to(inputs.device)\n",
    "        targets_2 = targets_2 * targets.reshape(-1, 1, 1, 1) + 1\n",
    "        x2 = torch.cat([inputs, targets_2 / S], dim=1)\n",
    "\n",
    "        inputs = torch.cat([x1, x2], dim=0)\n",
    "        targets = torch.cat([targets, targets], dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        t.set_description(f\"Epoch {epoch} Current Loss = {round(100.*correct/total, 3)}\", refresh=True)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            batch_size, _, H, W = inputs.shape\n",
    "\n",
    "            # creating \"blank\" inputs for the first inferense\n",
    "            # in this case, it's 4d tensor filled with constant C\n",
    "            targets_1 = C * torch.ones(batch_size, 1, H, W).to(inputs.device)\n",
    "            inputs = torch.cat([inputs, targets_1 / S], dim=1)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, f'./checkpoint/{args.checkpoint}.pth')\n",
    "        best_acc = acc\n",
    "\n",
    "    print(\"BEST ACCURACY: \", best_acc, \"Current Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705cb452",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5eb240-203c-49aa-883c-61c9fb8e3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "training_epochs = 40\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + training_epochs):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n",
    "    \n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] *= 0.01\n",
    "    \n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + training_epochs):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe7a9d",
   "metadata": {},
   "source": [
    "# OOD Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb47452",
   "metadata": {},
   "source": [
    "**CIFAR vs. SVHN OOD Evaluation:** In this subsection, we evaluate out-of-distribution (OOD) detection by testing our model trained on CIFAR10 against SVHN images, which contain classes not present in CIFAR10. We perform inference on both datasets and generate uncertainty estimates for each sample. We then compute standard ROC-AUC and PR-AUC metrics to assess in-distribution vs. out-of-distribution classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "print('==> Building model..')\n",
    "net = SimpleDLA()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa22e7",
   "metadata": {},
   "source": [
    "### Download pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ad720",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1qSCCl6hMMX65AVXms5kS7SYIA6e0fPkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a7b1b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pretrained weights, you could replace it with your weights file\n",
    "net.load_state_dict(torch.load(f\"./zigzag_pretrained_cifar.pth\", map_location='cpu')[\"net\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ed2f8",
   "metadata": {},
   "source": [
    "### Loading In- and Out-of-distribution Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ab10691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Loading SVHN data as OOD\n",
    "trainset_svhn = torchvision.datasets.SVHN(\n",
    "    root='./data', split=\"test\", download=True, transform=transform_test)\n",
    "trainloader_svhn = torch.utils.data.DataLoader(\n",
    "    trainset_svhn, batch_size=32, shuffle=True, num_workers=32)\n",
    "\n",
    "# Loading CIFAR test split as in-distribution\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=32, shuffle=False, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64ae165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some initializations before running inference\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "entropies = np.array([])\n",
    "ys = np.array([])\n",
    "\n",
    "net.eval()\n",
    "\n",
    "rc = 0\n",
    "counter = 0\n",
    "\n",
    "C = 0 # this parameter defines \"blank\" value for the input\n",
    "S = 10 # this parameter defines scale of the additional input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fae985",
   "metadata": {},
   "source": [
    "### Predict Uncertainties for In-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd799f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(testloader, total=len(testloader)):\n",
    "\n",
    "    X, y = batch\n",
    "\n",
    "    batch_size, _, H, W = X.shape\n",
    "\n",
    "    # creating \"blank\" inputs for the first inferense\n",
    "    # in this case, it's 4d tensor filled with constant C\n",
    "    targets_1 = C * torch.ones(batch_size, 1, H, W).to(X.device)\n",
    "    X1 = torch.cat([X, targets_1 / S], dim=1)\n",
    "\n",
    "    predictions = torch.nn.functional.softmax(net(X1), dim=1)\n",
    "    pred_labels = predictions.argmax(dim=1).cpu()\n",
    "\n",
    "    # creating additional input for the second inference\n",
    "    # in this case, this input filled with predicted classes\n",
    "    targets_2 = torch.ones(batch_size, 1, H, W).to(X.device)\n",
    "    targets_2 = targets_2 * pred_labels.reshape(-1, 1, 1, 1) + 1\n",
    "    X2 = torch.cat([X, targets_2 / S], dim=1)\n",
    "    \n",
    "    predictions_2 = torch.nn.functional.softmax(net(X2), dim=1)\n",
    "\n",
    "    unc = (predictions - predictions_2).max(dim=1)[0].detach().cpu().numpy()\n",
    "    y = np.zeros_like(y.cpu().numpy())\n",
    "\n",
    "    entropies = np.concatenate([entropies, unc])\n",
    "    ys = np.concatenate([ys, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c008b",
   "metadata": {},
   "source": [
    "### Predict Uncertainties for Out-of-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d824105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [00:17<00:00, 45.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(trainloader_svhn, total=len(trainloader_svhn)):\n",
    "\n",
    "    X, y = batch\n",
    "\n",
    "    batch_size, _, H, W = X.shape\n",
    "\n",
    "    # creating \"blank\" inputs for the first inferense\n",
    "    # in this case, it's 4d tensor filled with constant C\n",
    "    targets_1 = C * torch.ones(batch_size, 1, H, W).to(X.device)\n",
    "    X1 = torch.cat([X, targets_1 / S], dim=1)\n",
    "\n",
    "    predictions = torch.nn.functional.softmax(net(X1), dim=1)\n",
    "    pred_labels = predictions.argmax(dim=1).cpu()\n",
    "\n",
    "    # creating additional input for the second inference\n",
    "    # in this case, this input filled with predicted classes\n",
    "    targets_2 = torch.ones(batch_size, 1, H, W).to(X.device)\n",
    "    targets_2 = targets_2 * pred_labels.reshape(-1, 1, 1, 1) + 1\n",
    "    X2 = torch.cat([X, targets_2 / S], dim=1)\n",
    "\n",
    "    predictions_2 = torch.nn.functional.softmax(net(X2), dim=1)\n",
    "\n",
    "    unc = (predictions - predictions_2).max(dim=1)[0].detach().cpu().numpy()\n",
    "    y = np.ones_like(y.cpu().numpy())\n",
    "\n",
    "    entropies = np.concatenate([entropies, unc])\n",
    "    ys = np.concatenate([ys, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9fd58",
   "metadata": {},
   "source": [
    "### Computing AUC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee5b21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "roc_auc = sklearn.metrics.roc_auc_score(ys, entropies)\n",
    "\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(ys, entropies)\n",
    "pr_auc = sklearn.metrics.auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d49d912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOD ROC-AUC: 0.901, PR-AUC: 0.933\n"
     ]
    }
   ],
   "source": [
    "print(f\"OOD ROC-AUC: {round(roc_auc, 3)}, PR-AUC: {round(pr_auc, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
